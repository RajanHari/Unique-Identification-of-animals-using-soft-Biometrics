{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CTai ResNet18.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob5prOBOzlp-",
        "outputId": "3b6e65b6-25f2-4bf3-82ac-151e3f69a44e"
      },
      "source": [
        "!pwd\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnUVFNoxzz-l",
        "outputId": "746c81c0-9ba5-45f4-8994-0ac4d3d2a620"
      },
      "source": [
        "!git clone https://github.com/cvjena/chimpanzee_faces"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'chimpanzee_faces'...\n",
            "remote: Enumerating objects: 7252, done.\u001b[K\n",
            "remote: Total 7252 (delta 0), reused 0 (delta 0), pack-reused 7252\u001b[K\n",
            "Receiving objects: 100% (7252/7252), 602.71 MiB | 32.85 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n",
            "Checking out files: 100% (7210/7210), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gkg0MizYz5zc",
        "outputId": "44ce2ef8-6df1-42cb-a1ed-b5c95ad57638"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chimpanzee_faces  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7RmAPir0F3E",
        "outputId": "78756a80-fb62-4da3-dc56-460491afde53"
      },
      "source": [
        "cd chimpanzee_faces/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/chimpanzee_faces\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QRI9xCWZ0Iir",
        "outputId": "b8588adf-7545-47c8-9795-c0bcb101aea9"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/chimpanzee_faces'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RljaEtr0LCi",
        "outputId": "5241190e-4646-43ec-97c7-ec30ea9cfccf"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdatasets_cropped_chimpanzee_faces\u001b[0m/  initWorkspaceChimpanzeeFacesDataset.m\n",
            "\u001b[01;34mdemo_access_data\u001b[0m/                   README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfQgKLOY0L8e",
        "outputId": "13826894-0c96-45fd-c55d-d3401490d3c7"
      },
      "source": [
        "cd datasets_cropped_chimpanzee_faces/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/chimpanzee_faces/datasets_cropped_chimpanzee_faces\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWletSkj0PFb",
        "outputId": "8bec4870-e822-45de-8c1b-64afd1cc066b"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdata_CTai\u001b[0m/  \u001b[01;34mdata_CZoo\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1623iDr60Prc",
        "outputId": "4a4f2943-22be-4743-8a45-127076b812c8"
      },
      "source": [
        "cd data_CTai/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/chimpanzee_faces/datasets_cropped_chimpanzee_faces/data_CTai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RObycPog0RzP",
        "outputId": "6bdba9a9-bb7e-4043-f913-0cd258002e0a"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age_group_information.mat  \u001b[0m\u001b[01;34mface_images\u001b[0m/              identity_information.mat\n",
            "age_information.mat        filelist_face_images.txt  keypoint_information.mat\n",
            "annotations_ctai.txt       gender_information.mat    README_ChimpTai.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpXkCLYN0SI9",
        "outputId": "fde7d7ef-1518-476e-be7b-c9370e087de5"
      },
      "source": [
        "cd face_images"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/chimpanzee_faces/datasets_cropped_chimpanzee_faces/data_CTai/face_images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgwB8Z4X0Urj",
        "outputId": "64cd6623-cc5b-4fb0-a227-a104f26bcc87"
      },
      "source": [
        "cd -"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/chimpanzee_faces/datasets_cropped_chimpanzee_faces/data_CTai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vccbCfdm1Knw",
        "outputId": "f4d32437-47e1-4227-dbe5-f3382e84af8e"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/chimpanzee_faces/datasets_cropped_chimpanzee_faces/data_CTai'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTotDPLD1Ama"
      },
      "source": [
        "Filename face_images/img-id767-object-1.png Name Wapi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfWQA3kw0Y8i"
      },
      "source": [
        "file = open('annotations_ctai.txt','r')\n",
        "c=0\n",
        "imagenames = []\n",
        "nameofmonkey = []\n",
        "for line in file:\n",
        "  arr = line[:-1].split(\" \")[:4]\n",
        "  imagenames.append(arr[1])\n",
        "  nameofmonkey.append(arr[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R3Ld9CS1VpE",
        "outputId": "9bcc035c-1a2f-4bf2-d980-6b8ba2b7aba2"
      },
      "source": [
        "len(imagenames), len(nameofmonkey)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5078, 5078)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzpfIc8A1sGp",
        "outputId": "740df0a8-63b1-44d4-eee9-40754d547810"
      },
      "source": [
        "len(set(nameofmonkey))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c8C3IzX14Id"
      },
      "source": [
        "dnamecount = {}\n",
        "for name in nameofmonkey:\n",
        "  if name not in dnamecount:\n",
        "    dnamecount[name] = 1\n",
        "  else:\n",
        "    dnamecount[name] += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4EpJcKE8h2k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76085de1-bd95-4a72-8751-968206e9b8ed"
      },
      "source": [
        "dnamecount"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Adult': 416,\n",
              " 'Akouba': 1,\n",
              " 'Akrouba': 111,\n",
              " 'Akwaba': 90,\n",
              " 'Alina': 22,\n",
              " 'Athena': 63,\n",
              " 'Atra': 143,\n",
              " 'Baloo': 2,\n",
              " 'Besar': 22,\n",
              " 'Bienvenue': 16,\n",
              " 'Caramel': 94,\n",
              " 'Celine': 19,\n",
              " 'Coco': 72,\n",
              " 'Danane': 1,\n",
              " 'Diva': 2,\n",
              " 'Duna': 96,\n",
              " 'Endora': 33,\n",
              " 'Eva': 76,\n",
              " 'Fatima': 4,\n",
              " 'Freddy': 2,\n",
              " 'Fredy': 342,\n",
              " 'Garuda': 33,\n",
              " 'Gogol': 27,\n",
              " 'Haraka': 61,\n",
              " 'Huxel': 43,\n",
              " 'Ibrahiim': 1,\n",
              " 'Ibrahim': 28,\n",
              " 'Inousha': 35,\n",
              " 'Isha': 118,\n",
              " 'Jacobo': 65,\n",
              " 'Java': 17,\n",
              " 'Julia': 69,\n",
              " 'Kabisha': 23,\n",
              " 'Kaos': 69,\n",
              " 'Kinshasa': 174,\n",
              " 'Kiriku': 155,\n",
              " 'Kuba': 101,\n",
              " 'Liliou': 1,\n",
              " 'Lilou': 76,\n",
              " 'Linus': 36,\n",
              " 'Louise': 169,\n",
              " 'Lucas': 74,\n",
              " 'Mandy': 18,\n",
              " 'Marc': 3,\n",
              " 'Margot': 26,\n",
              " 'Max': 17,\n",
              " 'Mbeli': 11,\n",
              " 'Mkubwa': 57,\n",
              " 'Mustapha': 46,\n",
              " 'Olduvai': 3,\n",
              " 'Olivia': 86,\n",
              " 'Oscar': 61,\n",
              " 'Ravel': 12,\n",
              " 'Romario': 23,\n",
              " 'Rubra': 15,\n",
              " 'Sagu': 139,\n",
              " 'Sassandra': 90,\n",
              " 'Shogun': 171,\n",
              " 'Sumatra': 231,\n",
              " 'Taboo': 40,\n",
              " 'Tita': 41,\n",
              " 'Totem': 10,\n",
              " 'Utan': 99,\n",
              " 'Victor': 226,\n",
              " 'Virunga': 6,\n",
              " 'Voodoo': 3,\n",
              " 'Wala': 124,\n",
              " 'Wapi': 118,\n",
              " 'Wapii': 1,\n",
              " 'Wendy': 10,\n",
              " 'Woodstiock': 1,\n",
              " 'Woodstock': 87,\n",
              " 'Yao': 6,\n",
              " 'Yoghiti': 21,\n",
              " 'Yucca': 20,\n",
              " 'Zita': 42,\n",
              " 'Zora': 61,\n",
              " 'Zyon': 151}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlUUIPlI2w0a"
      },
      "source": [
        "excludenames = []\n",
        "for k,v in dnamecount.items():\n",
        "  if v<10:\n",
        "    excludenames.append(k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TJU6P0n53Qz",
        "outputId": "61963da1-878b-4016-d5de-ac42564f8149"
      },
      "source": [
        "print(len(excludenames), excludenames)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15 ['Fatima', 'Freddy', 'Ibrahiim', 'Akouba', 'Liliou', 'Diva', 'Danane', 'Wapii', 'Baloo', 'Marc', 'Woodstiock', 'Voodoo', 'Olduvai', 'Yao', 'Virunga']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzSG2SFl5_i5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a8d49fc-c7b3-4ee2-a75e-05885f4d8b68"
      },
      "source": [
        "id=0\n",
        "name_id_dict = {}\n",
        "for k,v in dnamecount.items():\n",
        "  if k not in excludenames:\n",
        "    name_id_dict[k] = id\n",
        "    id+=1\n",
        "id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vty0me_M7dKB"
      },
      "source": [
        "imagedirs = []\n",
        "monkeyids = []\n",
        "n = len(nameofmonkey)\n",
        "nd={}\n",
        "for i in range(n):\n",
        "  if nameofmonkey[i] not in excludenames:\n",
        "    imagedirs.append(imagenames[i])\n",
        "    monkeyids.append(name_id_dict[nameofmonkey[i]])\n",
        "    if nameofmonkey[i] not in nd:\n",
        "      nd[nameofmonkey[i]]=1\n",
        "    else:\n",
        "      nd[nameofmonkey[i]]+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkSiFIlg8B_i",
        "outputId": "c1287e5a-c5b7-4f69-c339-6a2f84418595"
      },
      "source": [
        "len(imagedirs), len(monkeyids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5041, 5041)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKxEu3bdC8CN",
        "outputId": "b20a9afb-4de7-4c70-da17-3612f4c61668"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(imagedirs,monkeyids, stratify=monkeyids, test_size=0.33)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, stratify=y_train, test_size=0.33)\n",
        "len(X_train), len(X_val), len(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2262, 1115, 1664)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfvf5YvL78t4"
      },
      "source": [
        "## imagedirs and monkeyids contain the image directories, and ids for each monkey respectively\n",
        "## X_val, X_test --> validation and test splits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkqYzVmtgWEE",
        "outputId": "da0618a4-e530-43f6-eb93-27e4582d76ee"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
        "model = nn.Sequential(*list(model.children())[:-1]).cuda()\n",
        "model.fc = nn.Sequential( \n",
        "                          nn.Flatten(start_dim=1),\n",
        "                          nn.Linear(512, 256),\n",
        "                          nn.Sigmoid(),\n",
        "                          nn.Dropout(0.2),\n",
        "                          nn.Linear(256, 63),\n",
        "                          nn.Softmax(dim=1)).cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP0NzcXSh055"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "\n",
        "class CTaiDataset(Dataset):\n",
        "    def __init__(self, inputs, outputs, transform):\n",
        "        self.main_dir = inputs\n",
        "        self.transform = transform\n",
        "        self.outputs = outputs\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.outputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.main_dir[idx]).convert(\"RGB\")\n",
        "        tensor_image = self.transform(image)\n",
        "        return {'image':tensor_image,'id':self.outputs[idx]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqdyCXQfzdZI"
      },
      "source": [
        "# experiments\n",
        "# ctai\n",
        "# another dataset\n",
        "# kl divergence loss\n",
        "# open set evaluation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pxl2y2SejSFE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e44501ef-001c-4e1a-b8d2-797ab08d20ba"
      },
      "source": [
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "trsfm = transforms.Compose([ \n",
        "                        transforms.Resize((224,224)),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_set = CTaiDataset(inputs=X_train, outputs=y_train, transform=trsfm)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=False, \n",
        "                               num_workers=4, drop_last=True)\n",
        "\n",
        "val_set = CTaiDataset(X_val, outputs=y_val, transform=trsfm)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=64, shuffle=False, \n",
        "                               num_workers=4, drop_last=True)\n",
        "\n",
        "test_set = CTaiDataset(X_test, outputs=y_test, transform=trsfm)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False, \n",
        "                               num_workers=4, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzmexVrx2-oL"
      },
      "source": [
        "# model = torch.load('model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoASKcKm1-0Q"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = True\n",
        "opt = optim.Adam(params=model.parameters(), lr=1e-3)\n",
        "celoss = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(50):\n",
        "  print(\"epoch\",epoch+1)\n",
        "  batch_loss, c, correct, total = 0,0,0,0\n",
        "  for idx, batch in enumerate(train_loader):\n",
        "    batch['image'] = batch['image'].float().cuda()\n",
        "    batch['id'] = batch['id'].cuda()\n",
        "    pred_op = model(batch['image'])\n",
        "    loss = celoss(pred_op,batch['id'])\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    batch_loss += loss.item()\n",
        "    correct += (pred_op.argmax(1) == batch['id']).float().sum().item()\n",
        "    total += batch['id'].shape[0]\n",
        "    print(end='\\r')\n",
        "    c+=1\n",
        "    print(\"batch\"+str(c),\"loss: \",loss.item(),\"batch_acc:\",correct/total, end='')\n",
        "    # batch['id'] = batch['id'].cuda()  \n",
        "  valloss = 0\n",
        "  correct, total = 0,0\n",
        "  for idx, batch in enumerate(val_loader):\n",
        "    # batch['image'] = batch['image'].cuda()\n",
        "    with torch.no_grad():\n",
        "      batch['image'] = batch['image'].float().cuda()\n",
        "      pred_op = model(batch['image'])\n",
        "      batch['id'] = batch['id'].cuda()\n",
        "      correct += (pred_op.argmax(1) == batch['id']).float().sum().item()\n",
        "      total += batch['id'].shape[0]\n",
        "      valloss += celoss(pred_op, batch['id'].cuda()).item()\n",
        "  valloss /= len(val_loader)\n",
        "  print(\"val_loss:\",valloss,\"val_acc:\",correct/total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_knzupHG34po"
      },
      "source": [
        "# RUN UNTIL HERE!!!!!!!!!!!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stcMg9_Nh4IA"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = True\n",
        "opt = optim.Adam(params=model.parameters(), lr=1e-3)\n",
        "celoss = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(50,100):\n",
        "  print(\"epoch\",epoch+1)\n",
        "  batch_loss, c, correct, total = 0,0,0,0\n",
        "  for idx, batch in enumerate(train_loader):\n",
        "    batch['image'] = batch['image'].float().cuda()\n",
        "    batch['id'] = batch['id'].cuda()\n",
        "    pred_op = model(batch['image'])\n",
        "    loss = celoss(pred_op,batch['id'])\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    batch_loss += loss.item()\n",
        "    correct += (pred_op.argmax(1) == batch['id']).float().sum().item()\n",
        "    total += batch['id'].shape[0]\n",
        "    print(end='\\r')\n",
        "    c+=1\n",
        "    print(\"batch\"+str(c),\"loss: \",loss.item(),\"batch_acc:\",correct/total, end='')\n",
        "    # batch['id'] = batch['id'].cuda()  \n",
        "  valloss = 0\n",
        "  correct, total = 0,0\n",
        "  for idx, batch in enumerate(val_loader):\n",
        "    # batch['image'] = batch['image'].cuda()\n",
        "    with torch.no_grad():\n",
        "      batch['image'] = batch['image'].float().cuda()\n",
        "      pred_op = model(batch['image'])\n",
        "      batch['id'] = batch['id'].cuda()\n",
        "      correct += (pred_op.argmax(1) == batch['id']).float().sum().item()\n",
        "      total += batch['id'].shape[0]\n",
        "      valloss += celoss(pred_op, batch['id'].cuda()).item()\n",
        "  valloss /= len(val_loader)\n",
        "  print(\"val_loss:\",valloss,\"val_acc:\",correct/total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X07bFLmlqd3H"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = True\n",
        "opt = optim.Adam(params=model.parameters(), lr=1e-3)\n",
        "celoss = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(100,150):\n",
        "  print(\"epoch\",epoch+1)\n",
        "  batch_loss, c, correct, total = 0,0,0,0\n",
        "  for idx, batch in enumerate(train_loader):\n",
        "    batch['image'] = batch['image'].float().cuda()\n",
        "    batch['id'] = batch['id'].cuda()\n",
        "    pred_op = model(batch['image'])\n",
        "    loss = celoss(pred_op,batch['id'])\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    batch_loss += loss.item()\n",
        "    correct += (pred_op.argmax(1) == batch['id']).float().sum().item()\n",
        "    total += batch['id'].shape[0]\n",
        "    print(end='\\r')\n",
        "    c+=1\n",
        "    print(\"batch\"+str(c),\"loss: \",loss.item(),\"batch_acc:\",correct/total, end='')\n",
        "    # batch['id'] = batch['id'].cuda()  \n",
        "  valloss = 0\n",
        "  correct, total = 0,0\n",
        "  for idx, batch in enumerate(val_loader):\n",
        "    # batch['image'] = batch['image'].cuda()\n",
        "    with torch.no_grad():\n",
        "      batch['image'] = batch['image'].float().cuda()\n",
        "      pred_op = model(batch['image'])\n",
        "      batch['id'] = batch['id'].cuda()\n",
        "      correct += (pred_op.argmax(1) == batch['id']).float().sum().item()\n",
        "      total += batch['id'].shape[0]\n",
        "      valloss += celoss(pred_op, batch['id'].cuda()).item()\n",
        "  valloss /= len(val_loader)\n",
        "  print(\"val_loss:\",valloss,\"val_acc:\",correct/total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VD2_XidOvFhT"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = True\n",
        "opt = optim.Adam(params=model.parameters(), lr=1e-3)\n",
        "celoss = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(150,300):\n",
        "  print(\"epoch\",epoch+1)\n",
        "  batch_loss, c, correct, total = 0,0,0,0\n",
        "  for idx, batch in enumerate(train_loader):\n",
        "    batch['image'] = batch['image'].float().cuda()\n",
        "    batch['id'] = batch['id'].cuda()\n",
        "    pred_op = model(batch['image'])\n",
        "    loss = celoss(pred_op,batch['id'])\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    batch_loss += loss.item()\n",
        "    correct += (pred_op.argmax(1) == batch['id']).float().sum().item()\n",
        "    total += batch['id'].shape[0]\n",
        "    print(end='\\r')\n",
        "    c+=1\n",
        "    print(\"batch\"+str(c),\"loss: \",loss.item(),\"batch_acc:\",correct/total, end='')\n",
        "    # batch['id'] = batch['id'].cuda()  \n",
        "  valloss = 0\n",
        "  correct, total = 0,0\n",
        "  for idx, batch in enumerate(val_loader):\n",
        "    # batch['image'] = batch['image'].cuda()\n",
        "    with torch.no_grad():\n",
        "      batch['image'] = batch['image'].float().cuda()\n",
        "      pred_op = model(batch['image'])\n",
        "      batch['id'] = batch['id'].cuda()\n",
        "      correct += (pred_op.argmax(1) == batch['id']).float().sum().item()\n",
        "      total += batch['id'].shape[0]\n",
        "      valloss += celoss(pred_op, batch['id'].cuda()).item()\n",
        "  valloss /= len(val_loader)\n",
        "  print(\"val_loss:\",valloss,\"val_acc:\",correct/total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhcuTIfXn161"
      },
      "source": [
        "torch.save(model,'model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VnqjI67czaaL",
        "outputId": "f4aaed27-c09f-4cd7-d91d-34ab9fb4a423"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('model.pth') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_10766d91-f89d-4543-bbbb-44f083cb2be8\", \"model.pth\", 45089673)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOmQ2u_4ppE7"
      },
      "source": [
        "testloss = 0\n",
        "correct, total = 0,0\n",
        "for idx, batch in enumerate(test_loader):\n",
        "  # batch['image'] = batch['image'].cuda()\n",
        "  with torch.no_grad():\n",
        "    batch['image'] = batch['image'].float().cuda()\n",
        "    pred_op = model(batch['image'])\n",
        "    batch['id'] = batch['id'].cuda()\n",
        "    correct += (pred_op.argmax(1) == batch['id']).float().sum().item()\n",
        "    total += batch['id'].shape[0]\n",
        "    testloss += celoss(pred_op, batch['id'].cuda()).item()\n",
        "testloss /= len(test_loader)\n",
        "print(\"test_loss:\",testloss,\"test_acc:\",correct/total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VxQVOt5zyHD"
      },
      "source": [
        "epoch 200\n",
        "train_loss:  3.433634042739868 train_acc: 0.6456801470588235\n",
        "val_loss: 3.7779698231640984 val_acc: 0.3915441176470588\n",
        "test_loss: 3.7770920991897583 test_acc: 0.3954326923076923"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY6ArIlsWsrc"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = True\n",
        "opt = optim.Adam(params=model.parameters(), lr=1e-3)\n",
        "celoss = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(50,100):\n",
        "  print(\"epoch\",epoch+1)\n",
        "  batch_loss, c, correct, total = 0,0,0,0\n",
        "  for idx, batch in enumerate(train_loader):\n",
        "    batch['image'] = batch['image'].float().cuda()\n",
        "    batch['id'] = batch['id'].cuda()\n",
        "    pred_op = model(batch['image'])\n",
        "    loss = celoss(pred_op,batch['id'])\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    batch_loss += loss.item()\n",
        "    correct += (pred_op.argmax(1) == batch['id']).float().sum().item()\n",
        "    total += batch['id'].shape[0]\n",
        "    print(end='\\r')\n",
        "    c+=1\n",
        "    print(\"batch\"+str(c),\"loss: \",loss.item(),\"batch_acc:\",correct/total, end='')\n",
        "    # batch['id'] = batch['id'].cuda()  \n",
        "  valloss = 0\n",
        "  correct, total = 0,0\n",
        "  for idx, batch in enumerate(val_loader):\n",
        "    # batch['image'] = batch['image'].cuda()\n",
        "    with torch.no_grad():\n",
        "      batch['image'] = batch['image'].float().cuda()\n",
        "      pred_op = model(batch['image'])\n",
        "      batch['id'] = batch['id'].cuda()\n",
        "      correct += (pred_op.argmax(1) == batch['id']).float().sum().item()\n",
        "      total += batch['id'].shape[0]\n",
        "      valloss += celoss(pred_op, batch['id'].cuda()).item()\n",
        "  valloss /= len(val_loader)\n",
        "  print(\"val_loss:\",valloss,\"val_acc:\",correct/total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5izXkCOWZnXV"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = True\n",
        "opt = optim.Adam(params=model.parameters(), lr=1e-3)\n",
        "celoss = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(100,150):\n",
        "  print(\"epoch\",epoch+1)\n",
        "  batch_loss, c, correct, total = 0,0,0,0\n",
        "  for idx, batch in enumerate(train_loader):\n",
        "    batch['image'] = batch['image'].float().cuda()\n",
        "    batch['id'] = batch['id'].cuda()\n",
        "    pred_op = model(batch['image'])\n",
        "    loss = celoss(pred_op,batch['id'])\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    batch_loss += loss.item()\n",
        "    correct += (pred_op.argmax(1) == batch['id']).float().sum().item()\n",
        "    total += batch['id'].shape[0]\n",
        "    print(end='\\r')\n",
        "    c+=1\n",
        "    print(\"batch\"+str(c),\"loss: \",loss.item(),\"batch_acc:\",correct/total, end='')\n",
        "    # batch['id'] = batch['id'].cuda()  \n",
        "  valloss = 0\n",
        "  correct, total = 0,0\n",
        "  for idx, batch in enumerate(val_loader):\n",
        "    # batch['image'] = batch['image'].cuda()\n",
        "    with torch.no_grad():\n",
        "      batch['image'] = batch['image'].float().cuda()\n",
        "      pred_op = model(batch['image'])\n",
        "      batch['id'] = batch['id'].cuda()\n",
        "      correct += (pred_op.argmax(1) == batch['id']).float().sum().item()\n",
        "      total += batch['id'].shape[0]\n",
        "      valloss += celoss(pred_op, batch['id'].cuda()).item()\n",
        "  valloss /= len(val_loader)\n",
        "  print(\"val_loss:\",valloss,\"val_acc:\",correct/total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZVEQS3YLBXz"
      },
      "source": [
        "for epoch in range(10,13):\n",
        "  print(\"epoch\",epoch+1)\n",
        "  batch_loss, c, correct, total = 0,0,0,0\n",
        "  for idx, batch in enumerate(train_loader):\n",
        "    batch['image'] = batch['image'].float().cuda()\n",
        "    batch['id'] = batch['id'].cuda()\n",
        "    pred_op = model(batch['image'])\n",
        "    loss = celoss(pred_op,batch['id'])\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    batch_loss += loss.item()\n",
        "    correct += (pred_op.argmax(1) == batch['id']).float().sum().item()\n",
        "    total += batch['id'].shape[0]\n",
        "    print(end='\\r')\n",
        "    c+=1\n",
        "    print(\"batch\"+str(c),\"loss: \",loss.item(),\"batch_acc:\",correct/total, end='')\n",
        "    # batch['id'] = batch['id'].cuda()  \n",
        "  valloss = 0\n",
        "  correct, total = 0,0\n",
        "  for idx, batch in enumerate(val_loader):\n",
        "    # batch['image'] = batch['image'].cuda()\n",
        "    with torch.no_grad():\n",
        "      batch['image'] = batch['image'].float().cuda()\n",
        "      pred_op = model(batch['image'])\n",
        "      batch['id'] = batch['id'].cuda()\n",
        "      correct += (pred_op.argmax(1) == batch['id']).float().sum().item()\n",
        "      total += batch['id'].shape[0]\n",
        "      valloss += celoss(pred_op, batch['id'].cuda()).item()\n",
        "  valloss /= len(val_loader)\n",
        "  print(\"val_loss:\",valloss,\"val_acc:\",correct/total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8UAM9YYCNcK"
      },
      "source": [
        "for epoch in range(13,20):\n",
        "  print(\"epoch\",epoch+1)\n",
        "  batch_loss, c, correct, total = 0,0,0,0\n",
        "  for idx, batch in enumerate(train_loader):\n",
        "    batch['image'] = batch['image'].float().cuda()\n",
        "    batch['id'] = batch['id'].cuda()\n",
        "    pred_op = model(batch['image'])\n",
        "    loss = celoss(pred_op,batch['id'])\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    batch_loss += loss.item()\n",
        "    correct += (pred_op.argmax(1) == batch['id']).float().sum().item()\n",
        "    total += batch['id'].shape[0]\n",
        "    print(end='\\r')\n",
        "    c+=1\n",
        "    print(\"batch\"+str(c),\"loss: \",loss.item(),\"batch_acc:\",correct/total, end='')\n",
        "    # batch['id'] = batch['id'].cuda()  \n",
        "  valloss = 0\n",
        "  correct, total = 0,0\n",
        "  for idx, batch in enumerate(val_loader):\n",
        "    # batch['image'] = batch['image'].cuda()\n",
        "    with torch.no_grad():\n",
        "      batch['image'] = batch['image'].float().cuda()\n",
        "      pred_op = model(batch['image'])\n",
        "      batch['id'] = batch['id'].cuda()\n",
        "      correct += (pred_op.argmax(1) == batch['id']).float().sum().item()\n",
        "      total += batch['id'].shape[0]\n",
        "      valloss += celoss(pred_op, batch['id'].cuda()).item()\n",
        "  valloss /= len(val_loader)\n",
        "  print(\"val_loss:\",valloss,\"val_acc:\",correct/total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE8h2-PWPCT9"
      },
      "source": [
        "for epoch in range(23,100):\n",
        "  print(\"epoch\",epoch+1)\n",
        "  batch_loss, c, correct, total = 0,0,0,0\n",
        "  for idx, batch in enumerate(train_loader):\n",
        "    batch['image'] = batch['image'].float().cuda()\n",
        "    batch['id'] = batch['id'].cuda()\n",
        "    pred_op = model(batch['image'])\n",
        "    loss = celoss(pred_op,batch['id'])\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    batch_loss += loss.item()\n",
        "    correct += (pred_op.argmax(1) == batch['id']).float().sum().item()\n",
        "    total += batch['id'].shape[0]\n",
        "    print(end='\\r')\n",
        "    c+=1\n",
        "    print(\"batch\"+str(c),\"loss: \",loss.item(),\"batch_acc:\",correct/total, end='')\n",
        "    # batch['id'] = batch['id'].cuda()  \n",
        "  valloss = 0\n",
        "  correct, total = 0,0\n",
        "  for idx, batch in enumerate(val_loader):\n",
        "    # batch['image'] = batch['image'].cuda()\n",
        "    with torch.no_grad():\n",
        "      batch['image'] = batch['image'].float().cuda()\n",
        "      pred_op = model(batch['image'])\n",
        "      batch['id'] = batch['id'].cuda()\n",
        "      correct += (pred_op.argmax(1) == batch['id']).float().sum().item()\n",
        "      total += batch['id'].shape[0]\n",
        "      valloss += celoss(pred_op, batch['id'].cuda()).item()\n",
        "  valloss /= len(val_loader)\n",
        "  print(\"val_loss:\",valloss,\"val_acc:\",correct/total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kWCVZp3jMiv"
      },
      "source": [
        "\n",
        "\n",
        "numpy_data = np.random.randn(100, 3, 24, 24)\n",
        "numpy_target = np.random.randint(0, 5, size=(100))\n",
        "\n",
        "dataset = MyDataset(numpy_data, numpy_target)\n",
        "loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=10,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=torch.cuda.is_available()\n",
        ")\n",
        "\n",
        "for batch_idx, (data, target) in enumerate(loader):\n",
        "    print('Batch idx {}, data shape {}, target shape {}'.format(\n",
        "        batch_idx, data.shape, target.shape))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_dpaQQr2aQ3"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.histplot(data=d, bins=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "M-LZORYe9S80",
        "outputId": "52bd8b71-1d31-4f4e-b3a5-a7e45e5a2d5e"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.histplot(data=nd, bins=70)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3f0b04bbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fxaZjD719tS"
      },
      "source": [
        "nameofmonkey = [d[name] for name in nameofmonkey]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}